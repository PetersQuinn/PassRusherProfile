import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import PolynomialFeatures
import statsmodels.api as sm
import re

#load the nfl data we will build our regression model with
NFLStats=pd.read_csv(r"C:\Users\quint\OneDrive\Desktop\Python\PassRusherProfile\Data\NFLData2024.csv")

#load all of last years salary data (accurate as of 3/8/2025)
SalaryStats=pd.read_excel(r"C:\Users\quint\OneDrive\Desktop\Python\PassRusherProfile\Data\SalaryData2024.xlsx")

# keep only relevant data from the nflstats (ignoring LHS vs RHS data)
NFL_filter=NFLStats[["player", "team_name", "position", "player_id","player_game_count", "assists", "franchise_id", "hits", "hurries", "misses", "pass_rush_percent", "pass_rush_snaps", "pass_snaps", "pressures", "prp", "sacks", "stops", "tackles"]]

#keep only relevant dat from the salary stats (ignoring team name as this will come from NFL_Filter once merged)
Salary_filter=SalaryStats[["Player", "Age","Total Value", "Avg./Year", "Total Guaranteed", "Fully Guaranteed", "Free Agency"]]

#remove all corners, safeties, interiors, and linebackers from the dataset
#was later discovered far more positions existed as potential outliers (like WR, QB, HB)
#these also had to be removed as the pass rush percentage was not able to remove them
NFL_filter=NFL_filter[NFL_filter["position"]!= "CB"]
NFL_filter=NFL_filter[NFL_filter["position"]!= "S"]
NFL_filter=NFL_filter[NFL_filter["position"]!= "LB"]
NFL_filter=NFL_filter[NFL_filter["position"]!= "DI"]
NFL_filter=NFL_filter[NFL_filter["position"]!= "QB"]
NFL_filter=NFL_filter[NFL_filter["position"]!= "WR"]
NFL_filter=NFL_filter[NFL_filter["position"]!= "HB"]
NFL_filter=NFL_filter[NFL_filter["position"]!= "TE"]

#used chat for this function, will need to verify and validate!!!!
def standardize_name(name):
    name = name.lower().strip()  # Lowercase & remove leading/trailing spaces
    name = re.sub(r"[^\w\s]", "", name)  # Remove special characters (apostrophes, hyphens, etc.)
    name = re.sub(r"\s+", " ", name)  # Replace multiple spaces with a single space
    return name

#standardizes names to make merging more accurate
NFL_filter["player"] = NFL_filter["player"].apply(standardize_name)
Salary_filter.loc[:, "Player"] = Salary_filter["Player"].apply(standardize_name)

#unfortunately there are a large number of salaried players who didn't take snaps in the 2024-2025 regular season
#these players have to be removed from the salary data
players_to_remove = [
    "frankie luvu", "kyron johnson", "cameron sample", "ryder anderson", "zach harrison",
    "deshaan dixon", "william bradleyking", "nate lynn", "jihad ward", "bj ojulari",
    "chris rumph ii", "drake jackson", "cj ravenell", "earnest brown iv", "bradley chubb",
    "malcolm koonce", "jonathan garvin", "grayson murphy", "bralen trice", "derrick mclendon ii",
    "durell nchami", "jeremiah martin", "marcus haynes", "ovie oghoufo", "josh onujiogu",
    "elliott brown", "jermaine johnson ii", "larrell murchison", "tanoh kpassagnon", "deatrich wise",
    "adedayo odeleye", "sam williams", "isaiah iton", "tyreke smith", "adetomiwa adebawore",
    "daniel grzesiak", "anthony goodlow", "justin eboigbe", "david ebuka agoha", "pat oconnor",
    "deslin alexandre", "tremon morrisbrash", "bj thompson", "chris collins", "john franklinmyers",
    "jamree kromah", "julius welschof", "kentavius street", "lj collier", "malik hamm",
    "thomas rush", "junior aho", "camron peterson", "mike morris", "viliami fehoko", "luiji vilain",
    "samson ebukam", "dashawn hand", "andrew farmer", "carl jones jr"
]

#remove players who are in the `players_to_remove` list
Salary_filter = Salary_filter[~Salary_filter["Player"].isin(players_to_remove)]

# Get unique player names from both datasets
nfl_players = set(NFL_filter["player"])
salary_players = set(Salary_filter["Player"])

'''
Had to comment out the code as it isn't necessary now, but was useful for identifying errors in data parsing.
# Find players in NFL data but NOT in Salary data
nfl_not_in_salary = nfl_players - salary_players

# Find players in Salary data but NOT in NFL data
salary_not_in_nfl = salary_players - nfl_players

print(NFL_filter.head())
print(len(NFL_filter)) 

print(Salary_filter.head())
print(len(Salary_filter)) 

# Print unmatched names
print("\nPlayers in NFL data but missing from Salary data:")
for player in nfl_not_in_salary:
    print(f"NFLFilter: {player}")

print("\nPlayers in Salary data but missing from NFL data:")
for player in salary_not_in_nfl:
    print(f"SalaryFilter: {player}")

# Count the number of mismatches for reference
print(f"\nTotal unmatched in NFL filter: {len(nfl_not_in_salary)}")
print(f"Total unmatched in Salary filter: {len(salary_not_in_nfl)}")
'''
# Merge salary data into NFL stats based on player name
Merged_Data = NFL_filter.merge(Salary_filter, left_on="player", right_on="Player", how="left")

# Drop duplicate "Player" column after merging
Merged_Data.drop(columns=["Player"], inplace=True)

#selecting only numeric features for regression analysis. Also chose to remove redundant and unimportant features (pass_snaps, player_game_count)
numeric_features = ["player_id","player_game_count", "assists", "franchise_id", "hits", "hurries", "misses", "pass_rush_percent", "pass_rush_snaps", "pass_snaps", "pressures", "prp", "sacks", "stops", "tackles", "Total Value", "Avg./Year", "Total Guaranteed", "Fully Guaranteed"]
Merged_numeric = Merged_Data[numeric_features]

#must validate that theres no collinearity in our features. This was accounted for with the removal of redundant features
corr_matrix = Merged_numeric.corr()
# Plot heatmap
plt.figure(figsize=(10,8))
sns.heatmap(corr_matrix, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Feature Correlation Heatmap")
#plt.show()

#we must set up the standardization first to ensure a sack count can be compared to a snap count, which are on different scales
scaler = StandardScaler()
Merged_scaled = pd.DataFrame(scaler.fit_transform(Merged_numeric), columns=numeric_features, index=Merged_numeric.index)

regression_results = {}

#Total Value Model (excluding collinearities)
#tackles (excluding "hurries" as input)**
X_tackles = df_scaled.drop(columns=["tackles", "hurries", "stops", "pressures"])  # Removing "hurries"
y_tackles = df_scaled["tackles"]

model_tackles = LinearRegression()
model_tackles.fit(X_tackles, y_tackles)

regression_results["tackles"] = {
    "RÂ² Score": model_tackles.score(X_tackles, y_tackles),
    "Coefficients": dict(zip(X_tackles.columns, model_tackles.coef_))
}